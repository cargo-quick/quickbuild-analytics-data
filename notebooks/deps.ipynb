{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargo dependency breakdown\n",
    "\n",
    "## Analogy\n",
    "\n",
    "so to give you an analogy, \n",
    "* MHRA is like a pizza shop where pizzas are made\n",
    "* there are many chefs working in the MHRA pizza shop and there are many pizza shops doing similar work to MHRA\n",
    "* a pizza (backend web server) has cheese (http library) and pizza base (database library)\n",
    "  * pizza base has dough (low-level database library)\n",
    "    * dough has flour (network library), salt (encryption library) and yeast (database query formatter) \n",
    "  * cheese has milk (http library) and salt (same encryption library)\n",
    "* *but*\n",
    "  * there are lots of different ways to make pizza base\n",
    "    * there are lots of different ways to make flour\n",
    "    * there are lots of different ways to make yeast\n",
    "  * there are lots of different ways to make cheese\n",
    "    * there are lots of different ways to make milk\n",
    "    * there are lots of different ways to make salt\n",
    "* it costs money to *pre-make different types of* dough, cheese and pizza base so we want to only *pre-make* the ingredients for the pizzas that people want\n",
    "* everything pre-built has a shelf life of 6 weeks (trust me on this one)\n",
    "* *so*\n",
    "* We want to pre-make only the most popular ingredients to maximise the *amount of time saved by* chefs making pizzas\n",
    "* and then we can have quick pizza in rust land for the masses and no one needs to go hungry again\n",
    "* ...does that make sense??\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "print(pio.renderers.default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = pandas.read_parquet(\"../subtrees-clean.parquet\")\n",
    "\n",
    "tree_counts = trees.groupby(\n",
    "    ['package_name', 'package_version', 'hash'],\n",
    ").agg(\n",
    "    tree_size=('deps_count', 'first'),\n",
    "    example_repo_path=('repo_path', 'first'),\n",
    "    tree_occurrences=('repo_path', 'count'),\n",
    ")\n",
    "\n",
    "version_counts = tree_counts.groupby(\n",
    "    ['package_name', 'package_version'],\n",
    ").agg(\n",
    "    version_occurrences=('tree_occurrences', 'sum'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_cached(fn):\n",
    "    import inspect\n",
    "    import hashlib\n",
    "    digest = hashlib.sha256(inspect.getsource(get_downloads_data).encode()).hexdigest()\n",
    "    cache_filename = f\"../cache/{fn.__name__}-{digest}.parquet\"\n",
    "\n",
    "    try:\n",
    "        data = pandas.read_parquet(cache_filename)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    data = fn()\n",
    "    data.to_parquet(cache_filename)\n",
    "    # TODO:\n",
    "    # * Delete every file matching f\"../cache/{fn.__name__}-*.parquet\"\n",
    "    #   other than `cache_filename`.\n",
    "    #   (or touch the file we used, if we want an LRU cache with size bigger than 1)\n",
    "    # * Log cache misses and timings.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_downloads_data():\n",
    "    conn = psycopg2.connect(\n",
    "        database=\"cratesio\",\n",
    "    )\n",
    "    downloads = pandas.read_sql_query(\"\"\"\n",
    "        select\n",
    "            c.name as package_name, v.num as package_version, d.downloads\n",
    "        from\n",
    "            version_downloads as d\n",
    "        join\n",
    "            versions as v on v.id = d.version_id\n",
    "        join\n",
    "            crates as c on c.id = v.crate_id\n",
    "        where\n",
    "            date = '2021-03-29'\n",
    "        order by\n",
    "            package_name, package_version\n",
    "        ;\n",
    "    \"\"\", conn)\n",
    "    return downloads\n",
    "\n",
    "downloads = call_cached(get_downloads_data).set_index(['package_name', 'package_version'])\n",
    "\n",
    "downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined = tree_counts.join(\n",
    "    version_counts,\n",
    "    how='inner',\n",
    "    on=['package_name', 'package_version']\n",
    ").join(\n",
    "    downloads,\n",
    "    how='inner',\n",
    "    on=['package_name', 'package_version'],\n",
    ")\n",
    "combined['estimated_daily_downloads'] = (\n",
    "    combined['downloads'] * combined['tree_occurrences'] / combined['version_occurrences']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unscaled(df, *, x, y, hover_name='package_name', color=None):\n",
    "    plot_data = df.reset_index().drop_duplicates(subset=[x, y])\n",
    "    fig = plotly.express.scatter(\n",
    "        plot_data, x=x, y=y, color=color,\n",
    "        hover_name=hover_name,\n",
    "    )\n",
    "    if hover_name is None:\n",
    "        fig.update_traces(hovertemplate=None, hoverinfo='skip')\n",
    "    return fig\n",
    "\n",
    "plot_unscaled(combined, x='tree_occurrences', y='tree_size', hover_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loglog(df, *, x, y, hover_name='package_name', color=None):\n",
    "    plot_data = df.reset_index().drop_duplicates(subset=[x, y])\n",
    "    fig = plotly.express.scatter(\n",
    "        plot_data, x=x, y=y, hover_name=hover_name, color=color,\n",
    "        log_x=True, log_y=True, \n",
    "    )\n",
    "    # fig.update_traces(hovertemplate=None, hoverinfo='skip')\n",
    "    return fig\n",
    "\n",
    "plot_loglog(combined, x='tree_occurrences', y='tree_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loglog(combined, x='estimated_daily_downloads', y='tree_size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "the utility gained by building a package tree is proportional to the number of users (tree_ocurrences) * the size of the tree (tree_size).\n",
    "\n",
    "    utility = tree_ocurrences * tree_size\n",
    "    log(utility) = log(tree_ocurrences * tree_size)\n",
    "    log(utility) = log(tree_ocurrences) + log(tree_size)\n",
    "\n",
    "therefore, lines of constant utility are straight downwards-sloping lines in the above log plot (we want to build the packages that are furthest to the top-right on this plot, like `frame-benchmarking`, `mio` and `winapi`)\n",
    "\n",
    "In practice, tree_ocurrences only says how many *GitHub Repos* are using particular configurations of the crates. We want to know how many *people* are using them. For this, we need to use the crates.io download data.\n",
    "\n",
    "## Caveats\n",
    "\n",
    "The set of requested features do not seem to appear in the lockfile. They only appear in Cargo.toml. In a lot of cases, changing features will add extra dependencies, but not always. We may need to re-do the analysis and create a new `subtrees-clean.parquet` that adds a \"features\" field to each dependency in the tree. This could be a lot of work with not great payoff though. Might be best to just keep in mind that the fragmentation will be a bit worse than what you see on these graphs.\n",
    "\n",
    "I am assuming that build time is proportional to dependency tree size. In reality, it is likely to also scale proportional to crate size (available as `versions.crate_size` in the crates.io postgresql dump), and whether it is using a lot of proc-macros and generics from its dependencies. Predicting crate build times would be a really interesting project, if anyone has a dataset (maybe crater has one?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw a line at 20% build-time-saved\n",
    "\n",
    "How many packages do we need to build in order to save 20% of people's time?\n",
    "\n",
    "Assuming:\n",
    "* Each crate is compiled once immediately after download and then never again (not true, but the repeated compiles probably scale with the number of downloads, so I'm hoping it falls out in the wash)\n",
    "* !!! Each crate takes a time proportional to its dependency count to compile (!!! I don't think that this is valid, because it assumes that there will be build time incurred by leaf dependencies at each layer above, even though the leaf dep's build time has already been counted based on the download count of the leaf dependency)\n",
    "* !!! It is possible to build a crate without building its leaf-dependencies (!!! In practice, in order to build a level-above crate, you need to reach into the quagmire and build the leaf-dependencies, even if we haven't identified them as good things to build)\n",
    "\n",
    "Let's just get a graph drawn and go from there, shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_loglog(combined, x='estimated_daily_downloads', y='tree_size')\n",
    "\n",
    "combined['time_wasted_compiling'] = combined['estimated_daily_downloads'] * combined['tree_size']\n",
    "time_wasted_compiling = combined['time_wasted_compiling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loglog(combined, x='estimated_daily_downloads', y='tree_size', color='time_wasted_compiling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_wasted_compiling.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_wasted_compiling = time_wasted_compiling.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_cost = time_wasted_compiling.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_cost[-1] / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['in_25_percent'] = cumulative_cost < (cumulative_cost[-1] / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loglog(combined, x='estimated_daily_downloads', y='tree_size', color='in_25_percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['in_25_percent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But what if we only care about downloads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_daily_downloads = combined['estimated_daily_downloads'].sort_values(ascending=False).cumsum()\n",
    "combined['cumulative_daily_downloads'] = cumulative_daily_downloads\n",
    "in_25_percent_downloads = cumulative_daily_downloads < (cumulative_daily_downloads[-1] / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_25_percent_downloads.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['in_25_percent_downloads'] = in_25_percent_downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_unscaled(combined, x='estimated_daily_downloads', y='cumulative_daily_downloads', color='in_25_percent_downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[in_25_percent_downloads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[in_25_percent_downloads].to_csv('../top_25_percent_downloads.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that could screw me over:\n",
    "\n",
    "* If a package version shows up in the crates.io download counts, but not in the github scraped lockfiles, I ignore it completely.\n",
    "* I still don't take into account features that don't affect the shape of the dependency tree. \n",
    "* I've not had very good sleep for 2 days straight, so I've probably made a mistake somewhere"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('qb-ATkvlelS-py3.9': poetry)",
   "name": "python394jvsc74a57bd0c9a4faaead04bde3041271e375671efe48c7c201b3423c55c116e9b87adb6cf8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "3be3f79b0d6c224c67b74ed101902d04f22489be2ee66d3ec7a43c28aa2c18b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
